{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../bin')\n",
    "\n",
    "from IPython.display import display\n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import \\\n",
    "    mean_absolute_error\n",
    "\n",
    "from utils import \\\n",
    "    UNITS, \\\n",
    "    anomaly_score, \\\n",
    "    check_std, \\\n",
    "    predict_intervals, \\\n",
    "    resample\n",
    "\n",
    "from train import \\\n",
    "    load_dataset, \\\n",
    "    load_datasets, \\\n",
    "    is_categorical, \\\n",
    "    create_dataset, \\\n",
    "    create_gb, \\\n",
    "    create_lr, \\\n",
    "    asym_loss, \\\n",
    "    create_mlp, \\\n",
    "    create_rf, \\\n",
    "    create_pipeline, \\\n",
    "    mean_absolute_percentage_error, \\\n",
    "    prediction_interval_coverage, \\\n",
    "    coverage_error, \\\n",
    "    evaluate_trials, \\\n",
    "    evaluate_cv\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trace Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file\n",
    "config = json.load(open('../workflows/kinc/params.json'))\n",
    "\n",
    "# load trace data\n",
    "dataset_names = [\n",
    "    'breast-palmetto',\n",
    "    'breast-google',\n",
    "    'unified-google'\n",
    "]\n",
    "data_map = {}\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    base_dir = '../_datasets/kinc-%s' % (dataset_name)\n",
    "\n",
    "    # aggregate minibench data before merging\n",
    "    df = load_dataset('%s/minibench.minibench.trace.txt' % (base_dir))\n",
    "    df = df.drop(columns=['hash', 'cpus', 'time', 'disk', 'memory'], errors='ignore')\n",
    "    df['gpu_flops'] = df['gpu_flops'].astype(np.float64)\n",
    "    df['gpu_mem_bw'] = df['gpu_mem_bw'].astype(np.float64)\n",
    "    df.loc[df['gpu_flops'].abs() > 1e7, 'gpu_flops'] = 0\n",
    "    df.loc[df['gpu_mem_bw'].abs() > 1e4, 'gpu_mem_bw'] = 0\n",
    "    df = df.groupby('node_type').mean()\n",
    "    df.to_csv('%s/minibench.minibench.trace.txt' % (base_dir), sep='\\t')\n",
    "\n",
    "    process_names = config['train_inputs'].keys()\n",
    "    merge_files = [arg.split(' ') for arg in config['train_merge_args']]\n",
    "\n",
    "    data_map[dataset_name] = load_datasets('kinc', process_names, base_dir=base_dir, merge_files=merge_files)\n",
    "\n",
    "# remove additional unused columns\n",
    "for dataset_name in data_map.keys():\n",
    "    for process_name, df in data_map[dataset_name].items():\n",
    "        df['platform'] = dataset_name.split('-')[1]\n",
    "        df = df.drop(columns=['hash', 'cpus', 'time', 'disk', 'memory', 'workdir', 'hostname'], errors='ignore')\n",
    "        data_map[dataset_name][process_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one similarity_chunk run for each unique workflow run\n",
    "for dataset_name in ['breast-palmetto']:\n",
    "    df = data_map[dataset_name]['similarity_chunk']\n",
    "\n",
    "    df = resample(df, ['dataset', 'n_rows', 'n_cols', 'hardware_type', 'chunks', 'threads', 'platform', 'node_type'])\n",
    "\n",
    "    display(df)\n",
    "\n",
    "    data_map[dataset_name]['similarity_chunk'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Cost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hourly rates for gcp resources (us-central1)\n",
    "gcp_rates = {\n",
    "    'e2_standard': {\n",
    "        'cpu': { 'ondemand': 0.021811, 'preempt': 0.006543 }, # per vCPU per hour\n",
    "        'mem': { 'ondemand': 0.002923, 'preempt': 0.000877 }  # per GB per hour\n",
    "    },\n",
    "    'e2_custom': {\n",
    "        'cpu': { 'ondemand': 0.022890, 'preempt': 0.006867 },\n",
    "        'mem': { 'ondemand': 0.003067, 'preempt': 0.000920 }\n",
    "    },\n",
    "    'n1_standard': {\n",
    "        'cpu': { 'ondemand': 0.031611, 'preempt': 0.006655 },\n",
    "        'mem': { 'ondemand': 0.004237, 'preempt': 0.000892 }\n",
    "    },\n",
    "    'n1_custom': {\n",
    "        'cpu': { 'ondemand': 0.033174, 'preempt': 0.00698 },\n",
    "        'mem': { 'ondemand': 0.004446, 'preempt': 0.00094 }\n",
    "    },\n",
    "    'n1_extended': {\n",
    "        'mem': { 'ondemand': 0.009550, 'preempt': 0.002014 }\n",
    "    },\n",
    "    'gpu': {\n",
    "        'p100': { 'ondemand': 1.46, 'preempt': 0.43 }, # per GPU per hour\n",
    "        'v100': { 'ondemand': 2.48, 'preempt': 0.74 }\n",
    "    },\n",
    "    'disk': {\n",
    "        'standard': 0.040 / 730, # per GB per hour\n",
    "        'ssd':      0.170 / 730,\n",
    "        'balanced': 0.100 / 730,\n",
    "        'extreme':  0.125 / 730\n",
    "    },\n",
    "    'storage': {\n",
    "        'standard': 0.0200 / 730, # per GB per hour\n",
    "        'nearline': 0.0100 / 730,\n",
    "        'coldline': 0.0040 / 730,\n",
    "        'archive':  0.0012 / 730\n",
    "    },\n",
    "    'storage_egress': {\n",
    "        '0.TB':  0.12, # per GB\n",
    "        '1.TB':  0.11,\n",
    "        '10.TB': 0.08\n",
    "    },\n",
    "    'storage_ops': {\n",
    "        'standard': { 'class_a': 0.050, 'class_b': 0.004 }, # per 10,000 ops\n",
    "        'nearline': { 'class_a': 0.100, 'class_b': 0.010 },\n",
    "        'coldline': { 'class_a': 0.100, 'class_b': 0.050 },\n",
    "        'archive':  { 'class_a': 0.500, 'class_b': 0.500 }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def gcp_cost_per_hour(x):\n",
    "    cost_per_hour = 0.0\n",
    "\n",
    "    # compute cpu cost\n",
    "    cpus = x.cpus if 'cpus' in x.index else 2 \n",
    "    cost_per_hour += gcp_rates['n1_custom']['cpu']['preempt'] * cpus\n",
    "\n",
    "    # compute memory cost\n",
    "    memory_GB = x.memory if 'memory' in x.index else 8\n",
    "    cost_per_hour += gcp_rates['n1_custom']['mem']['preempt'] * min(memory_GB, cpus * 6.5)\n",
    "\n",
    "    # compute extended memory cost\n",
    "    if memory_GB > cpus * 6.5:\n",
    "        cost_per_hour += gcp_rates['n1_extended']['mem']['preempt'] * (memory_GB - cpus * 6.5)\n",
    "\n",
    "    # compute gpu cost\n",
    "    if 'hardware_type' in x.index and x.hardware_type != 'cpu':\n",
    "        gpus = 1\n",
    "        gpu_type = x.hardware_type if x.hardware_type in {'p100', 'v100'} else 'v100'\n",
    "        cost_per_hour += gcp_rates['gpu'][gpu_type]['preempt'] * gpus\n",
    "\n",
    "    # compute disk cost\n",
    "    disk_GB = x.disk if 'disk' in x.index else 520\n",
    "    cost_per_hour += gcp_rates['disk']['standard'] * disk_GB\n",
    "\n",
    "    return cost_per_hour\n",
    "\n",
    "\n",
    "\n",
    "def gcp_storage_cost(storage_GB, storage_hr=0.0, egress=True, n_ops_a=0, n_ops_b=0):\n",
    "    storage_cost = 0.0\n",
    "\n",
    "    # compute storage cost\n",
    "    storage_cost += gcp_rates['storage']['standard'] * storage_GB * storage_hr\n",
    "\n",
    "    # compute egress cost\n",
    "    if egress:\n",
    "        storage_cost += gcp_rates['storage_egress']['0.TB'] * min(storage_GB, 1024)\n",
    "        storage_cost += gcp_rates['storage_egress']['1.TB'] * min(max(0, storage_GB - 1024), 10240)\n",
    "        storage_cost += gcp_rates['storage_egress']['10.TB'] * max(0, storage_GB - 10240)\n",
    "\n",
    "    # compute ops cost\n",
    "    storage_cost += gcp_rates['storage_ops']['standard']['class_a'] * n_ops_a / 10000\n",
    "    storage_cost += gcp_rates['storage_ops']['standard']['class_b'] * n_ops_b / 10000\n",
    "\n",
    "    return storage_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gcp costs for a few example operations\n",
    "x = pd.Series({\n",
    "    'cpus': 2,\n",
    "    'memory': 8,\n",
    "    'hardware_type': 'v100',\n",
    "    'disk': 520\n",
    "})\n",
    "storage_GB = 1000\n",
    "\n",
    "print('custom VM w/ V100: $%0.2f / hour' % (gcp_cost_per_hour(x)))\n",
    "print('store 1 TB:        $%0.3f / hour' % (gcp_storage_cost(storage_GB, storage_hr=1, egress=False)))\n",
    "print('store 1 TB:        $%0.0f / month' % (gcp_storage_cost(storage_GB, storage_hr=730, egress=False)))\n",
    "print('download 1 TB:     $%0.0f' % (gcp_storage_cost(storage_GB, storage_hr=0, egress=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Cost (Palmetto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_name, target = 'similarity_chunk', 'runtime_hr'\n",
    "\n",
    "# get performance data for pipeline / process\n",
    "df = data_map['breast-palmetto'][process_name]\n",
    "\n",
    "# HACK: minor adjustments\n",
    "df = df.sort_values('hardware_type')\n",
    "\n",
    "# estimate cost\n",
    "cost_per_hour = df.apply(gcp_cost_per_hour, axis=1)\n",
    "\n",
    "df['total_runtime_hr'] = df['runtime_hr'] * df['chunks']\n",
    "df['gcp_cost_usd'] = df['total_runtime_hr'] * cost_per_hour\n",
    "\n",
    "# plot runtime for various dataset sizes\n",
    "col = 'n_rows'\n",
    "x = 'n_cols'\n",
    "y = 'total_runtime_hr'\n",
    "hue = 'hardware_type'\n",
    "\n",
    "colors = plt.get_cmap('tab10').colors\n",
    "palette = {\n",
    "    'cpu': colors[0],\n",
    "    'p100': colors[1],\n",
    "    'v100': colors[2]\n",
    "}\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    df,\n",
    "    col=col,\n",
    "    sharey=False\n",
    ")\n",
    "g.map_dataframe(\n",
    "    sns.pointplot,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=hue,\n",
    "    markers='x',\n",
    "    linestyles='--',\n",
    "    palette=palette\n",
    ")\n",
    "g.add_legend(title=hue)\n",
    "plt.savefig('04-kinc-palmetto-runtime.pdf')\n",
    "plt.savefig('04-kinc-palmetto-runtime.png')\n",
    "plt.show()\n",
    "\n",
    "# plot estimated cast for various dataset sizes\n",
    "y = 'gcp_cost_usd'\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    df,\n",
    "    col=col,\n",
    "    sharey=False\n",
    ")\n",
    "g.map_dataframe(\n",
    "    sns.pointplot,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=hue,\n",
    "    markers='x',\n",
    "    linestyles='--',\n",
    "    palette=palette\n",
    ")\n",
    "g.add_legend(title=hue)\n",
    "plt.savefig('04-kinc-palmetto-cost.pdf')\n",
    "plt.savefig('04-kinc-palmetto-cost.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Cost (Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_processes = {'similarity_merge'}\n",
    "compute_cost = 0.0\n",
    "storage_GB = 0.0\n",
    "\n",
    "for process_name, df in data_map['unified-google'].items():\n",
    "    print()\n",
    "    print(process_name)\n",
    "\n",
    "    # get performance data for pipeline / process\n",
    "    if len(df) == 0:\n",
    "        print('no data, skipping')\n",
    "        continue\n",
    "\n",
    "    # estimate runtime cost\n",
    "    df['runtime_cost'] = df['runtime_hr'] * df.apply(gcp_cost_per_hour, axis=1)\n",
    "\n",
    "    # print results\n",
    "    print('compute cost: $%0.2f' % (df['runtime_cost'].sum()))\n",
    "    print('output data: %0.0f GB' % (df['disk_GB'].sum()))\n",
    "\n",
    "    # update totals\n",
    "    compute_cost += df['runtime_cost'].sum()\n",
    "\n",
    "    if process_name in output_processes:\n",
    "        storage_GB += df['disk_GB'].sum()\n",
    "    else:\n",
    "        print('note: intermediate outputs excluded from total storage/egress cost')\n",
    "\n",
    "# estimate storage cost\n",
    "storage_cost = gcp_storage_cost(storage_GB, storage_hr=730, egress=False)\n",
    "egress_cost = gcp_storage_cost(storage_GB, storage_hr=0, egress=True)\n",
    "\n",
    "# print results\n",
    "print()\n",
    "print('total output data: %0.0f GB' % (storage_GB))\n",
    "print()\n",
    "print('total compute cost: $%0.2f' % (compute_cost))\n",
    "print('total storage cost: $%0.2f / month' % (storage_cost))\n",
    "print('total egress cost:  $%0.2f' % (egress_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Cost (Palmetto/Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_name, target = 'similarity_chunk', 'runtime_hr'\n",
    "\n",
    "# get performance data for pipeline / process\n",
    "df_palmetto = data_map['breast-palmetto'][process_name]\n",
    "df_palmetto = df_palmetto[df_palmetto['hardware_type'] != 'cpu']\n",
    "df_google_a = data_map['breast-google'][process_name]\n",
    "df_google_b = data_map['unified-google'][process_name]\n",
    "\n",
    "df = pd.concat([\n",
    "    df_palmetto,\n",
    "    df_google_a,\n",
    "    df_google_b\n",
    "])\n",
    "inputs = config['train_inputs'][process_name]\n",
    "\n",
    "# remove samples with missing data\n",
    "df = df.drop(columns=['gcp_cost', 'runtime_cost'], errors='ignore')\n",
    "df = df.dropna()\n",
    "\n",
    "# compute ground truth cost\n",
    "df['gcp_cost_usd'] = df[target] * df.apply(gcp_cost_per_hour, axis=1)\n",
    "\n",
    "# remove inputs that have constant value\n",
    "inputs = [c for c in inputs if df[c].nunique() > 1]\n",
    "\n",
    "# append system metrics if appropriate\n",
    "if 'hardware_type' in inputs:\n",
    "    inputs.remove('hardware_type')\n",
    "    inputs += [\n",
    "        'cpu_flops',\n",
    "        'cpu_mem_bw',\n",
    "        'disk_read',\n",
    "        'disk_write',\n",
    "        'gpu_flops',\n",
    "        'gpu_mem_bw',\n",
    "    ]\n",
    "\n",
    "# perform parameter sweep\n",
    "df_scores = []\n",
    "y_preds = {}\n",
    "c_preds = {}\n",
    "\n",
    "n_rows_max = df_palmetto['n_rows'].max()\n",
    "n_rows_values = sorted(df_palmetto['n_rows'].unique())\n",
    "names = ['%0.2f' % (n_rows / n_rows_max) for n_rows in n_rows_values]\n",
    "\n",
    "for name, n_rows in zip(names, n_rows_values):\n",
    "    # extract datasets for system A, system B\n",
    "    df_a = df[((df['platform'] == 'palmetto') & (df['n_rows'] <= n_rows)) | ((df['platform'] == 'google') & df['dataset'].str.startswith('breast.001'))]\n",
    "    df_b = df[(df['platform'] == 'google') & (~df['dataset'].str.startswith('breast.001'))]\n",
    "\n",
    "    # create train/test sets for df_a, df_b\n",
    "    X_train, y_train, columns, _ = create_dataset(df_a, inputs, target)\n",
    "    X_test, y_test, _, _ = create_dataset(df_b, inputs, target)\n",
    "\n",
    "    # define model\n",
    "    model = create_pipeline(create_mlp(X_train.shape[1], intervals=True))\n",
    "\n",
    "    # train model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate model\n",
    "    y_bar, y_std = check_std(model.predict(X_test))\n",
    "    y_lower, y_upper = predict_intervals(y_bar, y_std)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_bar)\n",
    "    mpe = mean_absolute_percentage_error(y_test, y_bar)\n",
    "    cov = coverage_error(y_test, y_lower, y_upper)\n",
    "\n",
    "    # save metrics for plots\n",
    "    df_scores.append({\n",
    "        'name': name,\n",
    "        'mae': mae,\n",
    "        'mpe': mpe,\n",
    "        'cov': cov\n",
    "    })\n",
    "\n",
    "    # save predictions for plots\n",
    "    y_preds[name] = y_bar, y_std\n",
    "\n",
    "    # save cost predictions\n",
    "    cost_per_hour = df_b.apply(gcp_cost_per_hour, axis=1)\n",
    "\n",
    "    c_bar = y_bar * cost_per_hour\n",
    "    c_std = y_std * cost_per_hour\n",
    "    c_preds[name] = c_bar, c_std\n",
    "\n",
    "# save results\n",
    "df_scores = pd.DataFrame(df_scores)\n",
    "\n",
    "# plot evaluation scores for each model\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='name', y='mae', data=df_scores, ci=68, color='tab:blue')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('MAE (%s)' % (UNITS[target]))\n",
    "plt.plot(plt.xlim(), [df_b[target].median(), df_b[target].median()], 'r--')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='name', y='mpe', data=df_scores, ci=68, color='tab:blue')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.plot(plt.xlim(), [20, 20], 'r--')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='name', y='cov', data=df_scores, ci=68, color='tab:blue')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Coverage Error (%)')\n",
    "plt.plot(plt.xlim(), [5, 5], 'r--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot coverage profile for each model\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "for name, n_rows in zip(names, n_rows_values):\n",
    "    # extract datasets for system A, system B\n",
    "    df_a = df[((df['platform'] == 'palmetto') & (df['n_rows'] <= n_rows)) | ((df['platform'] == 'google') & df['dataset'].str.startswith('breast.001'))]\n",
    "    df_b = df[(df['platform'] == 'google') & (~df['dataset'].str.startswith('breast.001'))]\n",
    "\n",
    "    # create train/test sets for df_a, df_b\n",
    "    X_train, y_train, columns, _ = create_dataset(df_a, inputs, target)\n",
    "    X_test, y_test, _, _ = create_dataset(df_b, inputs, target)\n",
    "\n",
    "    # get model predictions\n",
    "    y_bar, y_std = y_preds[name]\n",
    "\n",
    "    # compute coverage profile\n",
    "    ci_values = np.arange(0.00, 1.00, 0.01)\n",
    "    cov_values = np.zeros_like(ci_values)\n",
    "\n",
    "    for i, ci in enumerate(ci_values):\n",
    "        y_lower, y_upper = predict_intervals(y_bar, y_std, ci=ci)\n",
    "        cov_values[i] = prediction_interval_coverage(y_test, y_lower, y_upper)\n",
    "\n",
    "    # plot coverage profile\n",
    "    plt.plot(100 * ci_values, 100 * cov_values, label=name)\n",
    "\n",
    "plt.plot([0, 100], [0, 100], 'k--', zorder=0)\n",
    "plt.legend(title='model')\n",
    "plt.xlabel('Confidence Interval (%)')\n",
    "plt.ylabel('Coverage (%)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot expected vs predicted target values for each model\n",
    "fig, axes = plt.subplots(1, len(names), figsize=(4 * len(names), 4), squeeze=False)\n",
    "\n",
    "for name, n_rows, ax in zip(names, n_rows_values, axes.flatten()):\n",
    "    # extract datasets for system A, system B\n",
    "    df_a = df[((df['platform'] == 'palmetto') & (df['n_rows'] <= n_rows)) | ((df['platform'] == 'google') & df['dataset'].str.startswith('breast.001'))]\n",
    "    df_b = df[(df['platform'] == 'google') & (~df['dataset'].str.startswith('breast.001'))]\n",
    "\n",
    "    # create train/test sets for df_a, df_b\n",
    "    X_train, y_train, columns, _ = create_dataset(df_a, inputs, target)\n",
    "    X_test, y_test, _, _ = create_dataset(df_b, inputs, target)\n",
    "\n",
    "    # get model predictions\n",
    "    y_bar, y_std = y_preds[name]\n",
    "    y_lower, y_upper = predict_intervals(y_bar, y_std)\n",
    "\n",
    "    # save model predictions\n",
    "    target_pred = '%s | %s' % (target, name)\n",
    "    df_b[target_pred] = y_bar\n",
    "\n",
    "    # save anomaly mask\n",
    "    anomaly_pred = 'anomaly | %s' % (name)\n",
    "    y_anomaly = anomaly_score(y_test, y_bar, y_std)\n",
    "    df_b[anomaly_pred] = (np.abs(y_anomaly) > 0.997)\n",
    "\n",
    "    # compute error bars\n",
    "    yerr = np.stack([\n",
    "        y_bar - y_lower,\n",
    "        y_upper - y_bar\n",
    "    ])\n",
    "\n",
    "    # create scatterplot\n",
    "    mask = ~df_b[anomaly_pred]\n",
    "    ax.errorbar(\n",
    "        x=target,\n",
    "        y=target_pred,\n",
    "        yerr=yerr[:, mask],\n",
    "        data=df_b[mask],\n",
    "        ecolor='tab:blue', c='tab:blue', ls='', marker='o', mec='w')\n",
    "\n",
    "    mask = df_b[anomaly_pred]\n",
    "    ax.errorbar(\n",
    "        x=target,\n",
    "        y=target_pred,\n",
    "        yerr=yerr[:, mask],\n",
    "        data=df_b[mask],\n",
    "        ecolor='tab:red', c='tab:red', ls='', marker='o', mec='w')\n",
    "\n",
    "    vmax = max(df_b[target].max(), df_b[target_pred].max())\n",
    "    ax.plot([0, vmax], [0, vmax], 'k--', zorder=0)\n",
    "    ax.set_xlabel(target)\n",
    "    ax.set_ylabel(target_pred)\n",
    "\n",
    "    cov = df_scores.loc[df_scores['name'] == name, 'cov']\n",
    "    ax.set_title('Coverage = %0.0f %%' % (100 - cov))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('04-kinc-palmetto-google-runtime.pdf')\n",
    "plt.savefig('04-kinc-palmetto-google-runtime.png')\n",
    "plt.show()\n",
    "\n",
    "# plot expected vs predicted cost for each model\n",
    "fig, axes = plt.subplots(1, len(names), figsize=(4 * len(names), 4), squeeze=False)\n",
    "\n",
    "for name, n_rows, ax in zip(names, n_rows_values, axes.flatten()):\n",
    "    # extract datasets for system A, system B\n",
    "    df_a = df[((df['platform'] == 'palmetto') & (df['n_rows'] <= n_rows)) | ((df['platform'] == 'google') & df['dataset'].str.startswith('breast.001'))]\n",
    "    df_b = df[(df['platform'] == 'google') & (~df['dataset'].str.startswith('breast.001'))]\n",
    "\n",
    "    # HACK: change target from runtime to cost\n",
    "    target = 'gcp_cost_usd'\n",
    "\n",
    "    # create train/test sets for df_a, df_b\n",
    "    X_train, y_train, columns, _ = create_dataset(df_a, inputs, target)\n",
    "    X_test, y_test, _, _ = create_dataset(df_b, inputs, target)\n",
    "\n",
    "    # get model predictions\n",
    "    y_bar, y_std = c_preds[name]\n",
    "    y_lower, y_upper = predict_intervals(y_bar, y_std)\n",
    "\n",
    "    # save model predictions\n",
    "    target_pred = 'gcp_cost_usd | %s' % (name)\n",
    "    df_b[target_pred] = y_bar\n",
    "\n",
    "    # save anomaly mask\n",
    "    anomaly_pred = 'anomaly | %s' % (name)\n",
    "    y_anomaly = anomaly_score(y_test, y_bar, y_std)\n",
    "    df_b[anomaly_pred] = (np.abs(y_anomaly) > 0.997)\n",
    "\n",
    "    # compute error bars\n",
    "    yerr = np.stack([\n",
    "        y_bar - y_lower,\n",
    "        y_upper - y_bar\n",
    "    ])\n",
    "\n",
    "    # create scatterplot\n",
    "    mask = ~df_b[anomaly_pred]\n",
    "    ax.errorbar(\n",
    "        x=target,\n",
    "        y=target_pred,\n",
    "        yerr=yerr[:, mask],\n",
    "        data=df_b[mask],\n",
    "        ecolor='tab:blue', c='tab:blue', ls='', marker='o', mec='w')\n",
    "\n",
    "    mask = df_b[anomaly_pred]\n",
    "    ax.errorbar(\n",
    "        x=target,\n",
    "        y=target_pred,\n",
    "        yerr=yerr[:, mask],\n",
    "        data=df_b[mask],\n",
    "        ecolor='tab:red', c='tab:red', ls='', marker='o', mec='w')\n",
    "\n",
    "    vmax = max(df_b[target].max(), df_b[target_pred].max())\n",
    "    ax.plot([0, vmax], [0, vmax], 'k--', zorder=0)\n",
    "    ax.set_xlabel(target)\n",
    "    ax.set_ylabel(target_pred)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('04-kinc-palmetto-google-cost.pdf')\n",
    "plt.savefig('04-kinc-palmetto-google-cost.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tesseract)",
   "language": "python",
   "name": "tesseract"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
